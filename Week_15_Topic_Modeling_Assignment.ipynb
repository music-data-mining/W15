{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHvFmq8NfyVs"
      },
      "source": [
        "# Week 15 Topic Modeling Assignment "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noLFDBxhC_Tx"
      },
      "source": [
        "In this assignment, you are expected to find a set of latent topics from the dataset we used in Lab.\n",
        "\n",
        "- use both term frequency representation, both unigrams and bigrams (hint: check out the `ngram_range` arg of `CountVectorizer()`) (1 pt)\n",
        "- build a LDA model for the task and tune paramters (e.g., `n_components`, `random_state`, `max_df`, and `min_df`) (1 pt)\n",
        "- print out most frequent 15 words for the latent topics and explain at least two of the topics (e.g., the 'season' one you saw in the lab notebook); the clustering doesn't need to be perfect, some overlap is fine. (1 pt)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M916HdUqf6ky"
      },
      "source": [
        "import os\n",
        "import csv\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import  LatentDirichletAllocation"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# git clone \"Music Dataset: Lyrics and Metadata from 1950 to 2019\"\n",
        "# the original corpus is adopted from https://data.mendeley.com/datasets/3t9vbwxgr5/2\n",
        "if os.path.exists('W15'): \n",
        "    !rm -fr 'W15/'\n",
        "!git clone https://github.com/music-data-mining/W15.git\n",
        "%cd W15"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Fw0Y6eImLb9",
        "outputId": "d2c4d668-db54-4b70-ddee-65c799821ee2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'W15'...\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 7 (delta 0), reused 7 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (7/7), done.\n",
            "/content/W15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nobz05Jckvn9"
      },
      "source": [
        "## Load Data\n",
        "\n",
        "Reusing lyrics from Music Dataset v2 ([*Music Dataset: Lyrics and Metadata from 1950 to 2019*](https://data.mendeley.com/datasets/3t9vbwxgr5/2))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "me8i7_AJkvoH"
      },
      "source": [
        "# read a relevant subset of the dataset\n",
        "lyrics = pd.read_csv('tcc_ceds_music.csv', \n",
        "                     usecols=['artist_name', 'track_name', 'release_date', 'genre', 'lyrics', 'topic'])   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare tf uni/bi-grams representation (1 pt)"
      ],
      "metadata": {
        "id": "nw965KEWM7Jt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbFun-gvkvoT",
        "outputId": "252fab37-0292-4300-fe18-6278cefb3ed3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It took 6.617960214614868 seconds to generate a TF unigram and bigram matrix for LDA\n",
            "tf_uni_bigram.shape:  (28372, 181415)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H14t7FLkvn8"
      },
      "source": [
        "## Find latent topics with LDA (1 pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdCbm9CFkvoe",
        "outputId": "55cb4eaf-747b-49f6-ca05-eee4496739c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It took 190.78402543067932 seconds to find LDA topics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Xgj408RrB-S",
        "outputId": "9fad1e98-9d81-43c4-a312-147694fff89d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THE TOP 15 WORDS FOR TOPIC #0\n",
            "['gonna', 'better', 'yeah', 'tell', 'time', 'think', 'know', 'late', 'doin', 'better better', 'say', 'need', 'rain', 'smoke', 'gonna gonna']\n",
            "THE TOP 15 WORDS FOR TOPIC #1\n",
            "['time', 'good', 'sing', 'song', 'time time', 'feel', 'like', 'good good', 'feel good', 'sing song', 'know', 'good time', 'songs', 'cause', 'long']\n",
            "THE TOP 15 WORDS FOR TOPIC #2\n",
            "['bout', 'talkin', 'learn', 'somebody', 'days', 'know', 'talkin bout', 'morning', 'night', 'talk', 'come', 'ghetto', 'tell', 'saturday', 'look']\n",
            "THE TOP 15 WORDS FOR TOPIC #3\n",
            "['life', 'live', 'know', 'wish', 'real', 'life life', 'live life', 'time', 'think', 'need', 'yeah', 'feel', 'like', 'cause', 'come']\n",
            "THE TOP 15 WORDS FOR TOPIC #4\n",
            "['like', 'come', 'know', 'cause', 'mind', 'change', 'stay', 'time', 'leave', 'play', 'shoot', 'say', 'hear', 'dead', 'look']\n",
            "THE TOP 15 WORDS FOR TOPIC #5\n",
            "['like', 'fuck', 'shit', 'know', 'bitch', 'yeah', 'nigga', 'cause', 'niggas', 'money', 'wanna', 'feel', 'come', 'want', 'real']\n",
            "THE TOP 15 WORDS FOR TOPIC #6\n",
            "['blue', 'like', 'look', 'time', 'know', 'goodbye', 'come', 'yeah', 'baby', 'tear', 'say', 'want', 'blue blue', 'cause', 'think']\n",
            "THE TOP 15 WORDS FOR TOPIC #7\n",
            "['head', 'know', 'cause', 'need', 'hate', 'high', 'head head', 'bitch', 'leave', 'grind', 'yeah', 'tell', 'baby', 'like', 'hand']\n",
            "THE TOP 15 WORDS FOR TOPIC #8\n",
            "['ready', 'know', 'come', 'forget', 'time', 'want', 'home', 'baby', 'yeah', 'waste', 'stand', 'ready ready', 'like', 'eye', 'tell']\n",
            "THE TOP 15 WORDS FOR TOPIC #9\n",
            "['world', 'stand', 'hear', 'come', 'know', 'girl', 'feel', 'little', 'stop', 'time', 'away', 'world world', 'stand stand', 'heart', 'think']\n",
            "THE TOP 15 WORDS FOR TOPIC #10\n",
            "['live', 'live live', 'come', 'woah', 'know', 'yeah', 'need', 'want', 'like', 'world', 'tell', 'dream', 'save', 'radio', 'hear']\n",
            "THE TOP 15 WORDS FOR TOPIC #11\n",
            "['wanna', 'know', 'like', 'want', 'think', 'wanna wanna', 'cause', 'come', 'dead', 'live', 'time', 'away', 'tire', 'gettin', 'hear']\n",
            "THE TOP 15 WORDS FOR TOPIC #12\n",
            "['come', 'home', 'christmas', 'come home', 'time', 'lonesome', 'wind', 'swing', 'warm', 'blow', 'hear', 'bell', 'leave', 'help', 'year']\n",
            "THE TOP 15 WORDS FOR TOPIC #13\n",
            "['heart', 'break', 'know', 'true', 'fool', 'come', 'lose', 'break heart', 'hurt', 'apart', 'kiss', 'leave', 'like', 'tear', 'darling']\n",
            "THE TOP 15 WORDS FOR TOPIC #14\n",
            "['long', 'know', 'dream', 'come', 'long long', 'time', 'night', 'thank', 'long time', 'sweet', 'night long', 'heart', 'say', 'tell', 'need']\n",
            "THE TOP 15 WORDS FOR TOPIC #15\n",
            "['night', 'play', 'come', 'devil', 'night night', 'know', 'sleep', 'fall', 'comin', 'right', 'like', 'cause', 'time', 'count', 'root']\n",
            "THE TOP 15 WORDS FOR TOPIC #16\n",
            "['home', 'music', 'come', 'like', 'home home', 'strong', 'head', 'roll', 'want', 'radio', 'time', 'know', 'lie', 'grow', 'walk']\n",
            "THE TOP 15 WORDS FOR TOPIC #17\n",
            "['right', 'know', 'fall', 'baby', 'yeah', 'money', 'right right', 'time', 'like', 'fall fall', 'come', 'yeah yeah', 'cause', 'money money', 'want']\n",
            "THE TOP 15 WORDS FOR TOPIC #18\n",
            "['alive', 'follow', 'come', 'play', 'everyday', 'fear', 'sleep', 'cause', 'hand', 'alive alive', 'dead', 'wrong', 'say', 'somethin', 'know']\n",
            "THE TOP 15 WORDS FOR TOPIC #19\n",
            "['feel', 'leave', 'black', 'cold', 'pain', 'like', 'feel feel', 'fall', 'shame', 'leave leave', 'sick', 'know', 'hear', 'want', 'need']\n",
            "THE TOP 15 WORDS FOR TOPIC #20\n",
            "['baby', 'sweet', 'wait', 'party', 'bring', 'know', 'need', 'want', 'come', 'love', 'yeah', 'night', 'like', 'dream', 'wait wait']\n",
            "THE TOP 15 WORDS FOR TOPIC #21\n",
            "['walk', 'lonely', 'love', 'time', 'know', 'night', 'walk away', 'right', 'baby', 'kill', 'mind', 'dream', 'cause', 'away', 'feel']\n",
            "THE TOP 15 WORDS FOR TOPIC #22\n",
            "['feel', 'fade', 'leave', 'hurt', 'change', 'away', 'hand', 'fade away', 'fever', 'want', 'easy', 'fall', 'hard', 'like', 'come']\n",
            "THE TOP 15 WORDS FOR TOPIC #23\n",
            "['fight', 'blood', 'inside', 'little', 'come', 'people', 'yeah', 'shoot', 'lord', 'cause', 'want', 'know', 'save', 'fight fight', 'free']\n",
            "THE TOP 15 WORDS FOR TOPIC #24\n",
            "['away', 'woman', 'away away', 'like', 'come', 'stay', 'cause', 'baby', 'know', 'want', 'right', 'turn', 'think', 'yeah', 'gonna']\n",
            "THE TOP 15 WORDS FOR TOPIC #25\n",
            "['life', 'change', 'know', 'away', 'time', 'want', 'like', 'heart', 'come', 'stay', 'dream', 'tear', 'eye', 'somebody', 'things']\n",
            "THE TOP 15 WORDS FOR TOPIC #26\n",
            "['tonight', 'hand', 'tonight tonight', 'ohoh', 'knock', 'come', 'leave', 'feel', 'today', 'cause', 'door', 'like', 'right', 'know', 'gonna']\n",
            "THE TOP 15 WORDS FOR TOPIC #27\n",
            "['hold', 'remember', 'miss', 'hold hold', 'know', 'feel', 'tight', 'belong', 'hell', 'arm', 'hold tight', 'right', 'hand', 'come', 'eye']\n",
            "THE TOP 15 WORDS FOR TOPIC #28\n",
            "['like', 'piece', 'burn', 'know', 'heart', 'fall', 'yeah', 'tell', 'roll', 'lover', 'come', 'save', 'leave', 'away', 'soul']\n",
            "THE TOP 15 WORDS FOR TOPIC #29\n",
            "['believe', 'mind', 'time', 'know', 'believe believe', 'want', 'whoa', 'feel', 'line', 'yeah', 'tell', 'mind mind', 'better', 'oooh', 'like']\n",
            "It took 126.75549411773682 seconds to generate LDA_topics.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explain the output (1 pt)\n",
        "Do you like the output? Spot two groups of words make sense to you and explain."
      ],
      "metadata": {
        "id": "0SlRhEHBNlia"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JymodmcUNxaD"
      }
    }
  ]
}